# Desafio TÃ©cnico â€“ Desenvolvedor(a) Back-end SÃªnior

Bem-vindo(a) ao desafio tÃ©cnico para a vaga de Pessoa Desenvolvedora Back-end SÃªnior!

Neste README estÃ£o detalhadas todas as informaÃ§Ãµes sobre a minha implementaÃ§Ã£o do desafio

## ğŸ“Œ Contexto

A Prefeitura do Rio de Janeiro quer oferecer aos cidadÃ£os uma **API de Carteira Digital**, onde os usuÃ¡rios poderÃ£o armazenar e gerenciar documentos digitais, consultar e carregar crÃ©ditos do transporte pÃºblico e acessar serviÃ§os municipais via chatbot.

O desafio Ã© desenvolver uma API para essa carteira digital, simulando as interaÃ§Ãµes do usuÃ¡rio com documentos e transporte pÃºblico.

## PrÃ©via
Antes de realizar as etapas para rodar o projeto, vocÃª pode visualizar a API que estÃ¡ disponÃ­vel publicamente em:

[https://api.iplan.thiagoandre.dev.br/docs](https://api.iplan.thiagoandre.dev.br/docs)
## Rodando o projeto
### Requisitos
 - Docker instalado
### Passo a passo
1) Clone o repo
```console
git clone https://github.com/thiago1591/desafio-senior-backend-developer
```
2) VÃ¡ atÃ© a pasta do projeto
```console
cd desafio-senior-backend-developer
```

3) Crie o .env

Crie um arquivo .env na raiz do projeto e copie para ele, o conteÃºdo do .env.example

4) Suba o docker
```console
docker-compose -f docker-compose.dev.yml up --build
```
Aguarde aparecer a mensagem `INFO:     Application startup complete.`

Esse comando irÃ¡ subir o Postgres, a API e o Jaeger (que serÃ¡ explicado mais adiante)

A API estarÃ¡ disponÃ­vel localmente na porta **8000**


## DocumentaÃ§Ã£o
A API estÃ¡ documentada no Swagger, acessando a rota [/docs](http://localhost:8000/docs)

Nela Ã© possÃ­vel ver em detalhes todos os endpoints disponÃ­veis, assim como os schemas.

## Estrutura do projeto
```
desafio-senior-backend-developer
â”œâ”€â”€ .github
â”‚   â”œâ”€â”€ workflows
â”‚   â”‚   â”œâ”€â”€ ci.yml
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ user
â”‚   â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â”œâ”€â”€ schemas.py 
â”‚   â”‚   â”œâ”€â”€ models.py 
â”‚   â”‚   â”œâ”€â”€ dependencies.py
â”‚   â”‚   â”œâ”€â”€ config.py 
â”‚   â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”‚   â”œâ”€â”€ service.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ ... (outros mÃ³dulos)
â”‚   â”œâ”€â”€ config.py  
â”‚   â”œâ”€â”€ models.py 
â”‚   â”œâ”€â”€ database.py  
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
...
```
A estrutura do projeto segue uma arquitetura modular, onde cada mÃ³dulo tem algumas camadas. Elas serÃ£o explicadas na prÃ³xima seÃ§Ã£o

## Camadas do mÃ³dulo
   1. `router.py` - Ã© o nÃºcleo de cada mÃ³dulo com todos os endpoints
   2. `schemas.py` - para os modelos Pydantic (define e valida os dados recebidos e retornados)
   3. `models.py` - modelos do banco de dados
   4. `service.py` - aqui estÃ£o as regras de negÃ³cio
   5. `dependencies.py` - dependencias do router
   8. `utils.py` - funÃ§Ãµes de utilitÃ¡rios
   9. `exceptions.py` - excessÃµes especÃ­ficas do mÃ³dulo, ex: `DocumentNotFound`

## Entidade Relacionamento
<img src="doc_images/er.png" alt="Logo" width="600"/>


## Testes
Os testes estÃ£o no diretÃ³rios `tests` na raiz do projeto. EstÃ£o implementados tanto testes de unidade quanto teste de integraÃ§Ã£o.

O objetivo dos testes de unidade Ã© testar a regra de negÃ³cio de forma completamente isolada. Ã‰ possÃ­vel testar cenÃ¡rios especÃ­ficos, como o caso do teste `test_multiple_recharges_accumulates_correctly` em que Ã© testado vÃ¡rias recargas no cartÃ£o de transporte em sequÃªncia e verificado se a soma Ã© acumulada corretamente.

Os testes de integraÃ§Ã£o, por outro lado, testam um cenÃ¡rio mais realista. O service nÃ£o Ã© testado isolado, mas sim junto com a rota e o banco de dados. Foi utilizado o SQlite como banco fake para realizaÃ§Ã£o dos testes de integraÃ§Ã£o.

Os testes sÃ£o executados automaticamente ao enviar um push. Se vocÃª quiser rodar manualmente, Ã© necessÃ¡rio rodar os testes de integraÃ§Ã£o separado dos de unidade. 
A variÃ¡vel TESTING=1 serve para impedir que o banco real Postgres inicialize

```console
docker exec -it desafio-senior-backend-developer-api-1 pytest -m unit
```
```console
docker exec -it desafio-senior-backend-developer-api-1 sh -c "TESTING=1 pytest -m integration"
```

```
â”œâ”€â”€ tests
â”‚   â”œâ”€â”€ integration
â”‚   â”‚   â”œâ”€â”€ test_auth.py
â”‚   â”‚   â”œâ”€â”€ test_documents.py
â”‚   â”‚   â”œâ”€â”€ test_transport.py
â”‚   â”‚   â”œâ”€â”€ test_users.py
â”‚   â”œâ”€â”€ unit
â”‚   â”‚   â”œâ”€â”€ documents
â”‚   â”‚   â”‚   â”œâ”€â”€ test_documents_service.py  
â”‚   â”‚   â”œâ”€â”€ transport
â”‚   â”‚   â”‚   â”œâ”€â”€ test_transport_service.py
â”‚   â”‚   â”œâ”€â”€ user
â”‚   â”‚   â”‚   â”œâ”€â”€ test_user_service.py

```
Foram criados 19 testes unitÃ¡rios e e 18 testes de integraÃ§Ã£o, totalizando 37 testes, que cobrem todas as funcionalidades exceto o chabot. Os testes testam tanto o caminho feliz quanto caminhos secundÃ¡rios.

## ğŸ”¹ Funcionalidades

- AutenticaÃ§Ã£o e Gerenciamento de UsuÃ¡rios
    - Cadastro e login de usuÃ¡rios (simples, com e-mail/senha).
    - Uso de tokens JWT para autenticaÃ§Ã£o.
    - AutenticaÃ§Ã£o com o Google
    - AutenticaÃ§Ã£o com o Meta
    - CRUD de usuÃ¡rios

- GestÃ£o de Documentos
    - Endpoints para armazenar, listar, atualizar e deletar documentos digitais (exemplo: identidade, CPF, comprovante de vacinaÃ§Ã£o).

- GestÃ£o de Transporte PÃºblico
    - Endpoint para buscar os meus cartÃµes de transporte pÃºblico
    - Endpoint para consultar saldo do passe de transporte pÃºblico
    - Endpoint para simular recarga e dÃ©bido do passe
    - Endpoint para ver o histÃ³rico de transaÃ§Ãµes

- IntegraÃ§Ã£o com Chatbot (Simples)
    - Consultar o saldo do passe pelo bot
    - Ver os meus documentos pelo bot
    - Fazer uma pergunta livre (resposta de perguntas mokadas)
    - Cancelar CartÃ£o (simulado, apenas diz que criou uma solicitaÃ§Ã£o de cancelamento)
    - Salvar documento (iniciado mas nÃ£o finalizado)

## OAuth2
AlÃ©m da autenticaÃ§Ã£o padrÃ£o com JWT, o sistema tambÃ©m possui opÃ§Ãµes de autenticaÃ§Ã£o com o Google e Meta. 

Para testar o OAuth2 social, Ã© necessÃ¡rio preencher os valores do .env referente ao Google e Meta com valores reais. Durante o desenvolvimento do case, criei um projeto/app no Google/Meta para obter as credenciais. Mas mesmo que eu colocasse minhas credenciais no example, outras pessoas nÃ£o conseguiriam testar o OAuth, pois como nÃ£o estÃ¡ em produÃ§Ã£o, eu precisaria adicionar o email do testador no painel, senÃ£o daria "App nÃ£o disponÃ­vel". Por esse motivo, estou colocando prints abaixo mostrando o funcionamento.

Para usar o OAuth do google, Ã© necessÃ¡rio acessar a rota diretamente do navegador (Swagger nÃ£o tem redirect)
`http://localhost:8000/auth/google/login`

O resultado Ã© a tela abaixo:

<img src="doc_images/oauth_google1.png" alt="Logo" width="600"/>

ApÃ³s selecionar a conta, leva para a rota de redirect (Ã© um endpoint da API)

<img src="doc_images/oauth_google2.png" alt="Logo" width="600"/>

Abaixo estÃ¡ o fluxo semelhante para o Meta

<img src="doc_images/oauth_meta1.png" alt="Logo" width="600"/>
<img src="doc_images/oauth_meta2.png" alt="Logo" width="600"/>

No endpoint de callback, eu estou apenas retornando as informaÃ§Ãµes obtidas, para verificar o funcionamento do OAuth.
Como nesse sistema a autenticaÃ§Ã£o Ã© com CPF e ele Ã© obrigatÃ³rio, em um fluxo real do frontend, o usuÃ¡rio ainda precisaria ir para outra 
pÃ¡gina para terminar o cadastro. Por conta disso, nÃ£o estou criando a conta do usuÃ¡rio direto no endpoint de callback (por ainda nÃ£o ter todas as informaÃ§Ãµes necessÃ¡rias)

## Rota de  SaÃºde
Ã© possÃ­vel testar se a API estÃ¡ rodando chamando o endpoint [/health](http://localhost:8000/health)

## Bot
Abaixo estÃ¡ um diagrama que mostra em mais detalhes as funcionalidades do bot

<img src="doc_images/bot_flow.png" alt="Logo" width="700"/>

Explicando mais tecnicamente, o bot tem 2 endpoints disponÃ­veis:
 - /chatbot/start
 - /chatbot/chat

O endpoint /chatbot/start Ã© usado apenas para listar a lista de opÃ§Ãµes do bot na primeira mensagem. Ã‰ importante pois o segundo endpoint, supoe que o usuÃ¡rio jÃ¡ escolheu o nÃºmero de uma opÃ§Ã£o disponÃ­vel.

O endpoint  /chatbot/chat recebe o token (com o user_id) e o input do usuÃ¡rio. Nas etapas principais, o input do usuÃ¡rio serÃ¡ um nÃºmero com a opÃ§Ã£o. 
Nesse momento, serÃ¡ chamada a camada de intent_dispatcher com o estado atual (que serÃ¡ criado se ainda nÃ£o existir) e o input do usuÃ¡rio. Essa camada serÃ¡ responsÃ¡vel por direcionar o fluxo para a intenÃ§Ã£o correspondente do usuÃ¡rio.

Mas o que Ã© o estado atual? 

Foi criada uma tabela chamada `chatbot_states`. 

<img src="doc_images/chatbot_er.png" alt="Logo" width="200"/>

O objetivo dessa tabela, Ã© permitir que o sistema crie uma mÃ¡quina de estados, de forma que, quando o usuÃ¡rio interagir, o sistema "lembre" em que parte do fluxo ele estÃ¡.

Por exemplo. Se o usuÃ¡rio quer consultar o saldo, ele digita a opÃ§Ã£o correspondente e recebe o saldo. Nesse caso o fluxo nÃ£o tem mais de 1 interaÃ§Ã£o, entÃ£o nÃ£o precisa salvar o estado.

Por outro lado, se o usuÃ¡rio quer fazer uma pergunta geral, ele primeiro precisa enviar uma mensagem com numero 5, para indicar que quer fazer uma pergunta. ApÃ³s isso, o bot irÃ¡ pedir para o usuÃ¡rio digitar a pergunta e ele irÃ¡ enviar outra requisiÃ§Ã£o com a pergunta. Nesse caso, Ã© preciso ter um estado salvo para "lembrar" que a Ãºltima interaÃ§Ã£o foi o usuÃ¡rio escolhendo que quer fazer uma pergunta e que o fluxo atual estÃ¡ recebendo a pergunta. 

O mesmo aconteceria para o fluxo de salvar documentos, que precisaria perguntar as informaÃ§Ãµes do documento para entÃ£o salvar no final (implementaÃ§Ã£o disso nÃ£o foi finalizada mas a tabela de estados jÃ¡ permitiria implementar)

```
â”œâ”€â”€ chatbot
â”‚   â”œâ”€â”€ services
â”‚   â”‚   â”‚   intent_handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ handle_cancel_card.py
â”‚   â”‚   â”‚   â”œâ”€â”€ handle_check_balance.py
â”‚   â”‚   â”‚   â”œâ”€â”€ handle_find_my_documents.py
â”‚   â”‚   â”‚   â”œâ”€â”€ handle_question.py
â”‚   â”‚   â”‚   â”œâ”€â”€ handle_save_document.py #nÃ£o finalizado
â”‚   â”‚   â”œâ”€â”€ intent_dispatcher.py
â”‚   â”œâ”€â”€ router.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ state_manager.py
â”‚   â”œâ”€â”€ ...
```

## SeparaÃ§Ã£o dos ambientes
O projeto possui 2 ambientes: dev e prod. Foram criados 2 Dockerfiles e 2 Docker Composes. Nesse README, os comandos jÃ¡ instruem para rodar corretamente o ambiente de dev, para testar localmente. As configuraÃ§Ãµes de produÃ§Ã£o foram utilizadas no deploy do projeto, que serÃ£o discutidas mais detalhadamente da seÃ§Ã£o de discussÃµes de decisÃµes.

## CI/CD
Em .github->workflows->ci.yml
estÃ¡ o arquivo da pipeline. Nela, estÃ¡ configurado para executar o github actions com os testes. Sempre que Ã© enviado um novo push, garantindo que novas alteraÃ§Ãµes nÃ£o quebrem funcionalidades existentes.

## Logging
na pasta src, existe um mÃ³dulo dedicado ao logging. Nele, estÃ¡ configurado apenas o log padrÃ£o do Python. Contudo, essa abstraÃ§Ã£o Ã© importante pois, caso fosse necessÃ¡rio implementar alguma ferramenta de logging (como por exemplo o Loki), entÃ£o bastaria implementar nesse mÃ³dulo e todo restante do cÃ³digo iria funcionar da mesma forma. 

Os logs sÃ£o uma ferramenta bem importante de estar configurada pois facilita a depuraÃ§Ã£o e correÃ§Ã£o de problemas que sÃ£o encontrados em produÃ§Ã£o. O ideal Ã© que jÃ¡ sejam configurados desde as etapas iniciais de uma API, por esse motivo coloquei esse esboÃ§o. 

No endpoint de criaÃ§Ã£o de usuÃ¡rio, eu coloquei alguns logs para mostrar como seria o funcionamento

## Tracing
O tracing Ã© outra ferramenta de observabilidade, para complementar os logs. Ele permite rastrear o fluxo de execuÃ§Ã£o de uma requisiÃ§Ã£o ao longo de diferentes partes do sistema, assim como o tempo de execuÃ§Ã£o em cada uma dessas partes. Eu usei o `OpenTelemetry` e implementei um exemplo, tambÃ©m no endpoint de criaÃ§Ã£o de usuÃ¡rio. 

No Docker Compose, adicionei um serviÃ§o do Jaeger. Ã‰ possÃ­vel acessar em 

http://localhost:16686

Esse painel jÃ¡ possui algumas ferramentas de observabilidade

## MigraÃ§Ãµes

Para gerenciamento das migraÃ§Ãµes, estou usando o [Aerich](https://tortoise-orm.readthedocs.io/en/latest/migration.html).

O histÃ³rico de migraÃ§Ãµes fica na pasta `/migrations`, na raiz do projeto.

### Criar uma nova migraÃ§Ã£o

Para criar uma nova migraÃ§Ã£o apÃ³s modificar os modelos, rode o seguinte comando:

```bash
docker compose exec desafio-senior-backend-developer-api-1 aerich migrate
```
Sempre que o container do Docker sobe, ele jÃ¡ roda `aerich upgrade`

## ğŸ”¹ Tecnologias

- FastAPI como framework principal.
- Banco de Dados PostgreSQL 
- ORM Tortoise-ORM
- Ferramenta de migrations Aerich
- PyTest
- OpenAPI para DocumentaÃ§Ã£o da API
- GitHub Actions
- Docker
- OpenTelemetry
- Jaeger

## ğŸ”¹ DiscussÃ£o de decisÃµes

### Escolha das tecnologias
O banco de dados escolhido foi o Postgres. Para o escopo dessa API, a escolha entre o MySQL e Postgres nÃ£o traria mudanÃ§as significativas. Optei pelo Postgres pois Ã© o banco que tenho maior preferÃªncia, apÃ³s realizar um estudo de comparaÃ§Ã£o entre esses 2 bancos, para escrita de um artigo durante a disciplina de AdministraÃ§Ã£o de Banco de Dados, na faculdade.
As outras tecnologias usadas foram escolhidas baseadas no que eu tenho mais familiaridade.

### Arquitetura em mÃ³dulos
Como esse Ã© um projeto simples, talvez nÃ£o fosse necessÃ¡rio o uso de uma arquitetura modular. PorÃ©m, decidi aqui aplicar uma organizaÃ§Ã£o que eu usaria para um projeto real. No passado, jÃ¡ tive problemas para manter projetos que nÃ£o usavam mÃ³dulos (imagine mais de 80 cruds em uma pasta cruds). Por isso hoje eu sempre utilizo uma abordagem modular. Como Ã© simples de entender a aplicar, faz sentido atÃ© mesmo para projetos menores, pois tambÃ©m garante que se um dia precisar, serÃ¡ possÃ­vel escalar.

### SeparaÃ§Ã£o das camadas dos mÃ³dulos
A separaÃ§Ã£o das camadas, que foi descrita na seÃ§Ã£o "Camadas do mÃ³dulo", Ã© algo que funciona muito bem e possui diversas vantagens. Ã‰ algo que Ã© um padrÃ£o usado em diferentes linguagens. Por exemplo, o NestJS (framework backend de Javascript) possui outros termos e nomenclaturas, mas segue uma ideia bem parecida.
Uma camada Ã© responsÃ¡vel por validar e tipar os dados de entrada e saÃ­da. Outra define as rotas dos endpoints. Outra define as regras de negÃ³cio. Outra define a modelagem da tabela e permite a conexÃ£o com o ORM.
As principais vantagens sÃ£o:
 - 1) manutenabilidade: Abrindo o arquivo de routes, Ã© possÃ­vel ter uma visÃ£o geral e legÃ­vel das rotas usadas no mÃ³dulo. ApÃ³s encontrar a rota que quer da manutenÃ§Ã£o, Ã© possÃ­vel facilmente encontrar o service correspondente. Como os arquivos estÃ£o em um mÃ³dulo, nÃ£o Ã© preciso ficar procurando, por exemplo, o arquivo de service dentro de uma pasta como vÃ¡rios services.
 - 2) testabilidade: separando as responsabilidades em diferentes camadas, fica mais fÃ¡cil de testar. Por exemplo, Ã© possÃ­vel criar testes de unidade de forma isolada para os services, pois eles estÃ£o separados e nÃ£o acoplados com as rotas.
 - 3) validaÃ§Ãµes: ter uma camada especÃ­fica para aplicar validaÃ§Ãµes Ã© muito vantajoso pois nÃ£o Ã© preciso validar tudo no service. Fica mais fÃ¡cil de adicionar mais validaÃ§Ãµes, deixando o sistema mais seguro sem prejudicar a legibilidade.

 ### DecisÃµes na modelagem
1) Na modelagem da tabela de Document, supus que todo documento pertence a um Ãºnico usuÃ¡rio (1:N), por conta disso, criei uma tabela do document com user_id em vez de uma tabela de document e outra user_documents.
2) Decidi modelar a tabela de Document de forma mais simples e genÃ©rica dado o escopo desse desafio, mas em um cenÃ¡rio real Ã© possÃ­vel que os diferentes tipos de documentos tivessem necessidade de campos adicionais
3) Decidi separar o cartÃ£o de transporte em uma tabela separada em vez de considerar como um documento na tabela de documentos pois existiria a possibilidade de o cartÃ£o de transporte ter mais atributos e funcionalidades especÃ­ficas no futuro
4) Decidi salvar o saldo como centavos (tipo int) pois Ã© uma boa prÃ¡tica para evitar problemas de arredondamentos em alguams linguagens 

### Sobre a recuperaÃ§Ã£o de senha
Decidi criar um mÃ³dulo separado para a recuperaÃ§Ã£o de senha pois Ã© o que eu faria em uma API real. Criei alguns endpoints para simular como seria o fluxo e coloquei um comentÃ¡rio onde seria a comunicaÃ§Ã£o com o serviÃ§o externo (SMS ou Email) para envio do cÃ³digo de recuperaÃ§Ã£o. Por conta do tempo acabei nÃ£o finalizando essa mÃ³dulo. 

### ConsideraÃ§Ã£o sobre o login
Nesse projeto, decidi que o login seria feito por CPF, por se tratar de um gerenciamento de documentos em um sistema de serviÃ§o pÃºblico. Contudo, na interface do Swagger, para funcionar o OAuth atravÃ©s do botÃ£o no canto direito superior da pÃ¡gina, Ã© necessÃ¡rio que o nome dos parÃ¢metros do login sejam "username" e "password". Por esse motivo talvez acabe gerando um pequena confusÃ£o, pois nÃ£o fica tÃ£o claro que deve ser inserido o CPF.

### ChatBOT
A funcionalidade do chatbot acredito que seja a funcionalidade desse desafio que poderia seguir diferentes caminhos. Eu achei que seria legal para o contexto desse desafio, usar o chatbot para realizar algumas das funcionalidades dos outros mÃ³dulos (como consultar saldo). TambÃ©m coloquei opÃ§Ã£o para ele responder uma pergunta qualquer, que Ã© a funcionalidade principal requerida no desafio. 
O bot responde perguntas verificando diretamente das perguntas existentes (que estÃ£o mokadas). Para uma funcionaldiade real, daria pra usar um banco de dados vetorial para armazenar diferentes perguntas e respostas. Quando o usuÃ¡rio fizesse uma nova pergunta, verificaria a similaridade no espaÃ§o vetorial para buscar a resposta mais relevante. TambÃ©m daria pra usar isso em conjunto com um LLM para passar as respostas mais similares para o contexto do LLM e responder uma resposta ainda mais precisa (tÃ©cnica de RAG). Ã‰ algo que eu implementei no meu TCC.

### Deploy
Como eu jÃ¡ tinha um domÃ­nio e uma mÃ¡quina rodando na AWS, decidi fazer o deploy da API apenas como um extra, para ter um ambiente em produÃ§Ã£o real.
O que eu fiz foi:
 - usei uma instÃ¢ncia EC2
 - clonei o repo na mÃ¡quina
 - rodei o docker de produÃ§Ã£o e configurei o env
 - cadastrei o subdomÃ­nio api.iplan.thiagoandre.dev no registrobr
 - usei o certbot para obter os certificados https do subdomÃ­nio
 - configurei o nginx

### Observabilidade
Decidi implementar um esboÃ§o de observabilidade hoje eu costumo implementar ao iniciar APIs. Ã‰ muito comum finalizar um sistema, ir para produÃ§Ã£o, aparecerem problemas e os usuÃ¡rios nÃ£o saberem explicar muito bem qual Ã© o problema, muito menos como reproduzir. A observabilidade resolve isso pois permite identificar em tempo real, o que economiza bastante tempo que seria basta tendo que debugar o cÃ³digo para tentar entender o que ocorreu.